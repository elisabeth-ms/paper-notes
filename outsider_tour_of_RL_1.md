## [Make It Happen](http://www.argmin.net/2018/01/29/taxonomy/)

The author motivates why RL is important compared to supervised and unsupervised learning.

### Key Points

<img src="https://user-images.githubusercontent.com/7057863/43361654-58b1aed6-9307-11e8-8431-692880d1940d.png" alt="drawing" width="400px"/>
<img src="https://user-images.githubusercontent.com/7057863/43361653-579f3e50-9307-11e8-944f-d62ca11c92b1.png" alt="drawing" width="400px"/>

- 
- 

### My two cents
I really like how this post motivates why studying adversarial examples is important beyond security concerns. In addition, the authors enumerate lots of interesting examples with references (e.g., [Do neural nets dream of electric sheep?](http://aiweirdness.com/post/171451900302/do-neural-nets-dream-of-electric-sheep), [The Shallowness of Google Translate](https://www.theatlantic.com/technology/archive/2018/01/the-shallowness-of-google-translate/551570/), and [Adversarial examples in the context of GMail spam filtering](https://elie.net/blog/ai/attacks-against-machine-learning-an-overview)) to illustrate their argument, which makes their points really convincing.
