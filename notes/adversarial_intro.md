## [A Brief Introduction to Adversarial Examples](http://people.csail.mit.edu/madry/lab/blog/adversarial/2018/07/06/adversarial_intro/)

The authors briefly introduce the definitoin of adversarial examples and **why it's really a thing**.

### Key Points

- Beyond security, studying adversarial examples can provide us insight on 
  - Robustness of ML-based system
  - Difference between ML-based system and human. (e.g., many models have achieved human-surpassing performance but not robust to small perturbation, which means that ML-based system works very differently compared to human.)
- Adversarial examples are beyond image classification. They also appear in other important applications such as speech recognition, question answering system.

### My two cents
I really like how this post motivates why studying adversarial examples is important beyond security concerns. In addition, the authors enumerate lots of interesting examples with references (e.g., [Do neural nets dream of electric sheep?](http://aiweirdness.com/post/171451900302/do-neural-nets-dream-of-electric-sheep), [The Shallowness of Google Translate](https://www.theatlantic.com/technology/archive/2018/01/the-shallowness-of-google-translate/551570/), and [Adversarial examples in the context of GMail spam filtering](https://elie.net/blog/ai/attacks-against-machine-learning-an-overview)) to illustrate their argument, which makes their points really convincing.
